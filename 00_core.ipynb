{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covid\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: Add documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import typing\n",
    "from typing import List, Callable\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import io\n",
    "import os\n",
    "from io import StringIO\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setDefaults(figsize=(18,6)):\n",
    "    sns.set_style(\"dark\")\n",
    "    sns.set(rc={'legend.fontsize':14,\n",
    "                'xtick.labelsize':14,\n",
    "                'ytick.labelsize':14,\n",
    "                'axes.labelsize':16,\n",
    "                'axes.titlesize':18,\n",
    "                'figure.figsize':figsize,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the names of the time series files published by JHU.  These names changed overnight on 24.03.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "CONFIRMED = 'time_series_covid19_confirmed_global.csv'\n",
    "DEATHS    = 'time_series_covid19_deaths_global.csv'\n",
    "RECOVERED = 'time_series_19-covid-Recovered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a couple of utility functions for returning yesterday and today as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "getToday: Callable[[None], str] = lambda: date.today().strftime('%m-%d-%Y')\n",
    "getYesterday: Callable[[None], str] = lambda: (date.today() - datetime.timedelta(days = 1)).strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two utility functions are used to process a JHU csv file and turn it into a `pandas` dataframe.  Note that the dataset changed a couple of column names on 24.03.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procDataframe(csv: str) -> pd.DataFrame:\n",
    "    ''' Convert csv file to a pandas dataframe. '''\n",
    "    df = pd.read_csv(csv)\n",
    "    try:\n",
    "        df['Province/State'].fillna('',inplace=True)\n",
    "    except:\n",
    "        df['Province_State'].fillna('',inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    cols = df.columns.to_list()\n",
    "    if 'Last Update' in cols:\n",
    "        df['Last Update'] = df['Last Update'].apply(pd.to_datetime)\n",
    "    if 'Last_Update' in cols:\n",
    "        df['Last_Update'] = df['Last_Update'].apply(pd.to_datetime)\n",
    "    return df\n",
    "\n",
    "def procUrl(url: str, download: bool, localfile: str=None, force: bool=False, verbose: bool=False) -> pd.DataFrame:\n",
    "    ''' Optionally download then process csv file at url converting it to a pandas dataframe. '''\n",
    "    if download:\n",
    "        if os.path.exists(localfile) and not force:\n",
    "            verbose and print(f'\"{localfile}\" already exists so will not overwrite')\n",
    "        else:\n",
    "            verbose and print(f'Downloading \"{localfile}\" from \"{url}\"...')\n",
    "            urllib.request.urlretrieve(url, localfile)\n",
    "        return procDataframe(localfile)\n",
    "    else:\n",
    "        s = requests.get(url).content\n",
    "        return procDataframe(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility method to return a `pandas` dataframe with a given day's daily report and then ploty it by `kind` which can be one of `[\"Confirmed\",\"Deaths\",\"Recovered\"]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getDailyReport(day: str, download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{day}.csv'\n",
    "    localfile = f'{day}.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def plotDailyReport(df: pd.DataFrame, topN: int=10, color: str='y', kind: str='Confirmed') -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = df.groupby('Country_Region')[kind].sum().sort_values(ascending=False)[:topN].\\\n",
    "      plot(ax=ax, kind='bar', color=color, stacked=False, figsize=(18,9))\n",
    "    ax.set_ylabel('Count', size=14)\n",
    "    ax.set_xlabel('Country', size=14)\n",
    "    ax.set_title(f'Total {kind} by top {topN} countries as of {getYesterday()}', size=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains three utility methods to return time series data for each of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` in a `pandas` dataframe given a url to a corresponding csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getTimeSeriesConfirmed(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{CONFIRMED}'\n",
    "    localfile = 'time_series_19-covid-Confirmed.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def getTimeSeriesDeaths(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{DEATHS}'\n",
    "    localfile = 'time_series_19-covid-Deaths.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def getTimeSeriesRecovered(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{RECOVERED}'\n",
    "    localfile = 'time_series_19-covid-Recovered.csv'\n",
    "    return procUrl(url, download, localfile, force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains methods to aggregate each of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` by county.\n",
    "Note that `force` and `download` are both set `True` in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procTimeSeriesDataframe(r: List) -> pd.DataFrame:\n",
    "    sdf = pd.DataFrame(r)\n",
    "    sdf['day'] = sdf['day'].apply(pd.to_datetime)\n",
    "    sdf.set_index('day', drop=True, inplace=True)\n",
    "    return sdf\n",
    "\n",
    "def procTimeSeries(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    r = []\n",
    "    countries = df.groupby('Country/Region')\n",
    "    cols = df.columns.to_list()\n",
    "    for country, group in countries:\n",
    "        total = []\n",
    "        for row_index, row in group.iterrows():\n",
    "            rvals = row.to_list()\n",
    "            if not len(total):\n",
    "                total = rvals[4:]\n",
    "                #print('first',total)\n",
    "            else:\n",
    "                #print('next',rvals[4:])\n",
    "                total = [a+b for a, b in zip(total, rvals[4:])]\n",
    "        for a, b in zip(cols[4:], total):\n",
    "            r.append({'day':a, 'country':country, 'confirmed':b})\n",
    "    return procTimeSeriesDataframe(r)\n",
    "\n",
    "procTimeSeriesDeaths: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesDeaths(download=True, force=True))\n",
    "procTimeSeriesConfirmed: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesConfirmed(download=True, force=True))\n",
    "procTimeSeriesRecovered: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesRecovered(download=True, force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility plotting method for the processed and aggregated time series dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plotCountryTimeSeries(df: pd.DataFrame, countries: List, kind: str) -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    for country in countries:\n",
    "        ax = df[df['country'] == country].plot(ax=ax, kind='line', figsize=(18,9))\n",
    "    ax.set_ylabel('Count', size=14)\n",
    "    ax.set_xlabel('Day', size=14)\n",
    "    ax.set_title(f'{kind} in {countries} as of {getYesterday()}', size=18)\n",
    "    ax.legend(ax.get_lines(),countries)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
