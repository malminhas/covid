{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covid\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: Add documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import typing\n",
    "from typing import List, Callable\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import io\n",
    "import os\n",
    "from io import StringIO\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Note that the name of these files changed overnight on 24.03.20\n",
    "CONFIRMED = 'time_series_covid19_confirmed_global.csv'\n",
    "DEATHS    = 'time_series_covid19_deaths_global.csv'\n",
    "RECOVERED = 'time_series_19-covid-Recovered.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "getToday: Callable[[None], str] = lambda: date.today().strftime('%m-%d-%Y')\n",
    "getYesterday: Callable[[None], str] = lambda: (date.today() - datetime.timedelta(days = 1)).strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procDataframe(csv: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv)\n",
    "    try:\n",
    "        df['Province/State'].fillna('',inplace=True)\n",
    "    except:\n",
    "        df['Province_State'].fillna('',inplace=True)\n",
    "    df.fillna(0,inplace=True)\n",
    "    cols = df.columns.to_list()\n",
    "    if 'Last Update' in cols:\n",
    "        df['Last Update'] = df['Last Update'].apply(pd.to_datetime)\n",
    "    if 'Last_Update' in cols:\n",
    "        df['Last_Update'] = df['Last_Update'].apply(pd.to_datetime)\n",
    "    return df\n",
    "\n",
    "def procUrl(url: str,download: bool,localfile: str=None,force: bool=False, verbose: bool=False) -> pd.DataFrame:\n",
    "    if download:\n",
    "        if os.path.exists(localfile) and not force:\n",
    "            verbose and print(f'\"{localfile}\" already exists so will not overwrite')\n",
    "        else:\n",
    "            verbose and print(f'Downloading \"{localfile}\" from \"{url}\"...')\n",
    "            urllib.request.urlretrieve(url,localfile)\n",
    "        return procDataframe(localfile)\n",
    "    else:\n",
    "        s = requests.get(url).content\n",
    "        return procDataframe(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getTimeSeriesConfirmed(download: bool=False,force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{CONFIRMED}'\n",
    "    localfile = 'time_series_19-covid-Confirmed.csv'\n",
    "    return procUrl(url,download,localfile,force)\n",
    "\n",
    "def getTimeSeriesDeaths(download: bool=False,force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{DEATHS}'\n",
    "    localfile = 'time_series_19-covid-Deaths.csv'\n",
    "    return procUrl(url,download,localfile,force)\n",
    "\n",
    "def getTimeSeriesRecovered(download: bool=False,force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{RECOVERED}'\n",
    "    localfile = 'time_series_19-covid-Recovered.csv'\n",
    "    return procUrl(url,download,localfile,force)\n",
    "\n",
    "def getDailyReport(day: str,download: bool=False,force: bool=False) -> pd.DataFrame:\n",
    "    url = f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{day}.csv'\n",
    "    localfile = f'{day}.csv'\n",
    "    return procUrl(url,download,localfile,force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procTimeSeriesDataframe(r: List) -> pd.DataFrame:\n",
    "    sdf = pd.DataFrame(r)\n",
    "    sdf['day'] = sdf['day'].apply(pd.to_datetime)\n",
    "    sdf.set_index('day',drop=True,inplace=True)\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procTimeSeries(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    r = []\n",
    "    countries = df.groupby('Country/Region')\n",
    "    cols = df.columns.to_list()\n",
    "    for country,group in countries:\n",
    "        total = []\n",
    "        for row_index, row in group.iterrows():\n",
    "            rvals = row.to_list()\n",
    "            if not len(total):\n",
    "                total = rvals[4:]\n",
    "                #print('first',total)\n",
    "            else:\n",
    "                #print('next',rvals[4:])\n",
    "                total = [a+b for a,b in zip(total,rvals[4:])]\n",
    "        for a, b in zip(cols[4:], total):\n",
    "            r.append({'day':a, 'country':country, 'confirmed':b})\n",
    "    return procTimeSeriesDataframe(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "procTimeSeriesDeaths: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesDeaths(download=True))\n",
    "procTimeSeriesConfirmed: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesConfirmed(download=True,force=True))\n",
    "procTimeSeriesRecovered: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesRecovered(download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plotCountryTimeSeries(df: pd.DataFrame,countries: List,kind: str) -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    for country in countries:\n",
    "        ax = df[df['country'] == country].plot(ax=ax,kind='line',figsize=(18,9))\n",
    "    ax.set_ylabel('Count', size=14)\n",
    "    ax.set_xlabel('Day', size=14)\n",
    "    ax.set_title(f'{kind} in {countries} as of {getYesterday()}',size=18)\n",
    "    ax.legend(ax.get_lines(),countries)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
