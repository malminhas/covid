{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covid\n",
    "\n",
    "> Utility methods to process the John Hopkins University Covid-19 dataset using [nbdev](http://nbdev.fast.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module has a dependency on the following Python libraries which have been added to the `requirements` field in `settings.ini`:\n",
    "* `requests`\n",
    "* `pandas`\n",
    "* `matplotlib`\n",
    "* `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import typing\n",
    "from typing import List, Callable\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import io\n",
    "import os\n",
    "from io import StringIO\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains some defaults for `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setDefaults(figsize=(18,9)):\n",
    "    sns.set_style(\"dark\")\n",
    "    sns.set(rc={'legend.fontsize':14,\n",
    "                'xtick.labelsize':14,\n",
    "                'ytick.labelsize':14,\n",
    "                'axes.labelsize':16,\n",
    "                'axes.titlesize':18,\n",
    "                'figure.figsize':figsize,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the names of the time series files published by John Hopkins University (JHU).  Note that the format of these names changed overnight on 24.03.20 without prior warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ROOT      = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data'\n",
    "CONFIRMED = 'time_series_covid19_confirmed_global.csv'\n",
    "DEATHS    = 'time_series_covid19_deaths_global.csv'\n",
    "RECOVERED = 'time_series_19-covid-Recovered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graphing current counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a couple of utility functions for returning yesterday and today as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "getToday: Callable[[None], str] = lambda: date.today().strftime('%m-%d-%Y')\n",
    "getYesterday: Callable[[None], str] = lambda: (date.today() - datetime.timedelta(days = 1)).strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two utility functions are used to process a JHU csv file and turn it into a `pandas` dataframe.  Note that the dataset changed a couple of column names on 24.03.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procDataframe(csv: str) -> pd.DataFrame:\n",
    "    ''' Convert input csv data or file to a pandas dataframe. '''\n",
    "    assert(csv)\n",
    "    df = pd.read_csv(csv)\n",
    "    try:\n",
    "        df['Province/State'].fillna('',inplace=True)\n",
    "    except:\n",
    "        df['Province_State'].fillna('',inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    cols = df.columns.to_list()\n",
    "    if 'Last Update' in cols:\n",
    "        df['Last Update'] = df['Last Update'].apply(pd.to_datetime)\n",
    "    if 'Last_Update' in cols:\n",
    "        df['Last_Update'] = df['Last_Update'].apply(pd.to_datetime)\n",
    "    return df\n",
    "\n",
    "def procUrl(url: str, download: bool, localfile: str=None, force: bool=False, verbose: bool=False) -> pd.DataFrame:\n",
    "    ''' Optionally download then process csv data or file at url converting it to a pandas dataframe. '''\n",
    "    assert(url)\n",
    "    if download:\n",
    "        if os.path.exists(localfile) and not force:\n",
    "            verbose and print(f'\"{localfile}\" already exists so will not overwrite')\n",
    "        else:\n",
    "            verbose and print(f'Downloading \"{localfile}\" from \"{url}\"...')\n",
    "            urllib.request.urlretrieve(url, localfile)\n",
    "        return procDataframe(localfile)\n",
    "    else:\n",
    "        s = requests.get(url).content\n",
    "        return procDataframe(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility method to return a `pandas` dataframe with a given day's daily report and then ploty it by `kind` which can be one of `[\"Confirmed\",\"Deaths\",\"Recovered\"]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getCountriesDailyReport(day: str, download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    assert(len(day))\n",
    "    url = f'{ROOT}/csse_covid_19_daily_reports/{day}.csv'\n",
    "    localfile = f'{day}.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def plotCountriesDailyReport(df: pd.DataFrame, topN: int=10, color: str='y', kind: str='Confirmed') -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = df.groupby('Country_Region')[kind].sum().sort_values(ascending=False)[:topN].\\\n",
    "      plot(ax=ax, kind='bar', color=color, stacked=False, figsize=(18,9))\n",
    "    ax.set_ylabel('Count', size=14)\n",
    "    ax.set_xlabel('Country', size=14)\n",
    "    ax.set_title(f'Total {kind} by top {topN} countries as of {getYesterday()}', size=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graphing time series counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains three utility methods to return time series data for each of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` in a `pandas` dataframe given a url to a corresponding csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getTimeSeriesConfirmed(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'{ROOT}/csse_covid_19_time_series/{CONFIRMED}'\n",
    "    localfile = 'time_series_19-covid-Confirmed.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def getTimeSeriesDeaths(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'{ROOT}/csse_covid_19_time_series/{DEATHS}'\n",
    "    localfile = 'time_series_19-covid-Deaths.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def getTimeSeriesRecovered(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'{ROOT}/csse_covid_19_time_series/{RECOVERED}'\n",
    "    localfile = 'time_series_19-covid-Recovered.csv'\n",
    "    return procUrl(url, download, localfile, force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains methods to aggregate each of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` by county.  Note that `force` and `download` are both set `True` in all cases.  Note also that at time of writing `Recovered` isn't supported as a time series dataset in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procTimeSeriesDataframe(r: List) -> pd.DataFrame:\n",
    "    sdf = pd.DataFrame(r)\n",
    "    sdf['day'] = sdf['day'].apply(pd.to_datetime)\n",
    "    sdf.set_index('day', drop=True, inplace=True)\n",
    "    return sdf\n",
    "\n",
    "def procTimeSeries(df: pd.DataFrame, kind: str) -> pd.DataFrame:\n",
    "    r = []\n",
    "    countries = df.groupby('Country/Region')\n",
    "    cols = df.columns.to_list()\n",
    "    for country, group in countries:\n",
    "        total = []\n",
    "        for row_index, row in group.iterrows():\n",
    "            rvals = row.to_list()\n",
    "            if not len(total):\n",
    "                total = rvals[4:]\n",
    "                #print('first',total)\n",
    "            else:\n",
    "                #print('next',rvals[4:])\n",
    "                total = [a+b for a, b in zip(total, rvals[4:])]\n",
    "        for a, b in zip(cols[4:], total):\n",
    "            r.append({'day':a, 'country':country, kind:b})\n",
    "    return procTimeSeriesDataframe(r)\n",
    "\n",
    "procTimeSeriesDeaths: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesDeaths(download=True, force=True), 'Deaths')\n",
    "procTimeSeriesConfirmed: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesConfirmed(download=True, force=True), 'Confirmed')\n",
    "#procTimeSeriesRecovered: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesRecovered(download=True, force=True), 'Recovered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility plotting method for the processed and aggregated time series dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plotCountryTimeSeries(df: pd.DataFrame, countries: List, kind: str) -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    for country in countries:\n",
    "        ax = df[df['country'] == country].plot(ax=ax, y=kind, kind='line', figsize=(18,9))\n",
    "    ax.set_ylabel('Count', size=14)\n",
    "    ax.set_xlabel('Day', size=14)\n",
    "    ax.set_title(f'{kind} in {countries} as of {getYesterday()}', size=18)\n",
    "    ax.legend(ax.get_lines(),countries)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graphing counts and time series via Covid API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility method for plotting a sorted stacked bar graph of country data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plotCountriesDailyReportFromAPI(normalised=False):\n",
    "    url = 'https://api.covid19api.com/summary'\n",
    "    if normalised:\n",
    "        df = pd.DataFrame(requests.get(url).json().get('Countries'))\n",
    "        df.Country.replace({'Iran (Islamic Republic of)': 'Iran', 'Korea, South': 'South Korea'},inplace=True)\n",
    "        cols = df.columns.to_list()\n",
    "        sdf = df.groupby('Country')[cols[2:]].apply(sum).reset_index()\n",
    "        sdf = sdf.sort_values(by=['TotalConfirmed'], ascending=False)\n",
    "        _ = sdf[sdf.TotalDeaths > 10].plot(kind='bar', x='Country', y=['TotalConfirmed', 'TotalDeaths'],\\\n",
    "          color='yr', stacked=True, figsize=(18, 9)).set_title('Covid-19 cases and deaths', size=18)\n",
    "    else:\n",
    "        df = pd.DataFrame(requests.get(url).json().get('Countries')).\\\n",
    "          sort_values(by=['TotalConfirmed'], ascending=False)\n",
    "        _ = df[df.TotalDeaths > 10].plot(kind='bar', x='Country', y=['TotalConfirmed', 'TotalDeaths'],\\\n",
    "          color='yr', stacked=True, figsize=(18, 9)).set_title('Covid-19 cases and deaths', size=18)\n",
    "        \n",
    "def plotCategoryByCountry(category, country, color='y'):\n",
    "    url = f'https://api.covid19api.com/total/country/{country}/status/{category.lower()}'\n",
    "    df = pd.DataFrame(requests.get(url).json())\n",
    "    df['Date'] = df['Date'].apply(pd.to_datetime)\n",
    "    df.plot(kind='line', x='Date', y='Cases', color=color, figsize=(18, 9)).\\\n",
    "      set_title(f'Covid-19 {category} in {country}', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [the nbdev documentation](http://nbdev.fast.ai/test/):\n",
    "> Everything that is not an exported cell is considered a test, so you should make sure your notebooks can all run smoothly (and fast) if you want to use this functionality as the CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
