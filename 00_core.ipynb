{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covid\n",
    "\n",
    "> Utility methods to process the John Hopkins University Covid-19 dataset using [nbdev](http://nbdev.fast.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module has a dependency on the following Python libraries which have been added to the `requirements` field in `settings.ini`:\n",
    "* `requests`\n",
    "* `pandas`\n",
    "* `matplotlib`\n",
    "* `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('svg')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "import typing\n",
    "from typing import List, Callable\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import io\n",
    "import os\n",
    "from io import StringIO\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) # for handling log(0)\n",
    "\n",
    "ALTAIR_W = 750\n",
    "ALTAIR_H = 375\n",
    "\n",
    "alt.renderers.enable('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains some defaults for `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setDefaults(figsize=(18,9)):\n",
    "    sns.set_style(\"dark\")\n",
    "    sns.set(rc={'legend.fontsize':14,\n",
    "                'xtick.labelsize':14,\n",
    "                'ytick.labelsize':14,\n",
    "                'axes.labelsize':16,\n",
    "                'axes.titlesize':18,\n",
    "                'figure.figsize':figsize,\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the names of the time series files published by John Hopkins University (JHU).  Note that the format of these names changed overnight on 24.03.20 without prior warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ROOT      = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data'\n",
    "CONFIRMED = 'time_series_covid19_confirmed_global.csv'\n",
    "DEATHS    = 'time_series_covid19_deaths_global.csv'\n",
    "RECOVERED = 'time_series_19-covid-Recovered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graphing current counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a couple of utility functions for returning yesterday and today as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "getToday: Callable[[None], str] = lambda: date.today().strftime('%m-%d-%Y')\n",
    "getYesterday: Callable[[None], str] = lambda: (date.today() - datetime.timedelta(days = 1)).strftime('%m-%d-%Y')\n",
    "getDayBeforeYesterday: Callable[[None], str] = lambda: (date.today() - datetime.timedelta(days = 2)).strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two utility functions are used to process a JHU csv file and turn it into a `pandas` dataframe.  Note that the dataset changed a couple of column names on 24.03.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procDataframe(csv: str) -> pd.DataFrame:\n",
    "    ''' Convert input csv data or file to a pandas dataframe. '''\n",
    "    assert(csv)\n",
    "    df = pd.read_csv(csv)\n",
    "    if df.empty == True:\n",
    "        print(f'Empty data frame - are you sure the file/url exists?')\n",
    "        return df\n",
    "    try:\n",
    "        df['Province/State'].fillna('',inplace=True)\n",
    "    except:\n",
    "        df['Province_State'].fillna('',inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    cols = df.columns.to_list()\n",
    "    if 'Last Update' in cols:\n",
    "        df['Last Update'] = df['Last Update'].apply(pd.to_datetime)\n",
    "    if 'Last_Update' in cols:\n",
    "        df['Last_Update'] = df['Last_Update'].apply(pd.to_datetime)\n",
    "    return df\n",
    "\n",
    "def procUrl(url: str, download: bool, localfile: str=None, force: bool=False, verbose: bool=False) -> pd.DataFrame:\n",
    "    ''' Optionally download then process csv data or file at url converting it to a pandas dataframe. '''\n",
    "    assert(url)\n",
    "    if download:\n",
    "        if os.path.exists(localfile) and not force:\n",
    "            verbose and print(f'\"{localfile}\" already exists so will not overwrite')\n",
    "        else:\n",
    "            verbose and print(f'Downloading \"{localfile}\" from \"{url}\"...')\n",
    "            urllib.request.urlretrieve(url, localfile)\n",
    "        return procDataframe(localfile)\n",
    "    else:\n",
    "        s = requests.get(url).content\n",
    "        return procDataframe(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility method to return a `pandas` dataframe with a given day's daily report and then ploty it by `kind` which can be one of `[\"Confirmed\",\"Deaths\",\"Recovered\"]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getCountriesDailyReport(day: str, download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    assert(len(day))\n",
    "    url = f'{ROOT}/csse_covid_19_daily_reports/{day}.csv'\n",
    "    localfile = f'{day}.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def removeGrid(chart: alt.Chart) -> alt.Chart:\n",
    "    return chart.\\\n",
    "    configure_axis(\n",
    "        grid=False\n",
    "    ).configure_view(\n",
    "        strokeWidth=0\n",
    "    )\n",
    "\n",
    "def plotCountriesDailyReport(df: pd.DataFrame, which: str, topN: int=10, color: str='y',\n",
    "                             kind: str='Confirmed', grid: bool=True, visualisation: str='matplotlib') -> None:\n",
    "    if df.empty == True:\n",
    "        print(f'Empty data frame - are you sure the file/url exists?')\n",
    "        return df\n",
    "    if visualisation == 'altair':\n",
    "        sdf = df.groupby('Country_Region')[kind].sum().sort_values(ascending=False)[:topN]\n",
    "        keys = sdf.keys().to_list()\n",
    "        vals = sdf.to_list()\n",
    "        data = []\n",
    "        for k,v in zip(keys,vals):\n",
    "            data.append({'Country':k, kind: v})\n",
    "        sdf = pd.DataFrame(data)\n",
    "        bar_chart = alt.Chart(sdf).mark_bar(size=30).encode(\n",
    "            x=alt.X('Country',sort='-y'),\n",
    "            y=kind,\n",
    "            color=alt.value(color),\n",
    "            opacity=alt.value(0.9),\n",
    "        ).properties(\n",
    "            width=ALTAIR_W,\n",
    "            height=ALTAIR_H,\n",
    "            title=f'Total {kind} by top {topN} countries as of {which}'\n",
    "        )\n",
    "        if not grid:\n",
    "            bar_chart = removeGrid(bar_chart)\n",
    "        return bar_chart\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax = df.groupby('Country_Region')[kind].sum().sort_values(ascending=False)[:topN].\\\n",
    "          plot(ax=ax, kind='bar', color=color, stacked=False, figsize=(18,9))\n",
    "        ax.set_ylabel(kind, size=14)\n",
    "        ax.set_xlabel('Country', size=14)\n",
    "        ax.set_title(f'Total {kind} by top {topN} countries as of {which}', size=18)\n",
    "        plt.show()\n",
    "\n",
    "def plotCountryDailyReport(df: pd.DataFrame, country: str, which: str, topN: int=10, color: str='orange',\n",
    "                           kind: str='Confirmed', grid: bool=True, visualisation: str='matplotlib') -> None:\n",
    "    if df.empty == True:\n",
    "        print(f'Empty data frame - are you sure the file/url exists?')\n",
    "        return df\n",
    "    if visualisation == 'altair':\n",
    "        sdf = df[df['Country_Region'] == country].groupby('Province_State')[kind].sum().sort_values(ascending=False)[:topN]\n",
    "        keys = sdf.keys().to_list()\n",
    "        vals = sdf.to_list()\n",
    "        data = []\n",
    "        for k,v in zip(keys,vals):\n",
    "            data.append({'Province_State':k, kind: v})\n",
    "        sdf = pd.DataFrame(data)\n",
    "        bar_chart = alt.Chart(sdf).mark_bar(size=30).encode(\n",
    "            x=alt.X('Province_State',sort='-y'),\n",
    "            y=kind,\n",
    "            color=alt.value(color),\n",
    "            opacity=alt.value(0.9),\n",
    "        ).properties(\n",
    "            width=ALTAIR_W,\n",
    "            height=ALTAIR_H,\n",
    "            title=f'Total {kind} for top {topN} regions of {country} as of {which}'\n",
    "        )\n",
    "        if not grid:\n",
    "            bar_chart = removeGrid(bar_chart)\n",
    "        return bar_chart\n",
    "    else:\n",
    "        ax = df[df['Country_Region'] == country].groupby('Province_State')[kind].sum().sort_values(ascending=False)[:topN].\\\n",
    "          plot(kind='bar', color=color, stacked=False, figsize=(18,9))\n",
    "        ax.set_ylabel(kind, size=14)\n",
    "        ax.set_xlabel('Country', size=14)\n",
    "        ax.set_title(f'Total {kind} for top {topN} regions of {country} as of {which}', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graphing time series counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains three utility methods to return time series data for each of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` in a `pandas` dataframe given a url to a corresponding csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getTimeSeriesConfirmed(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'{ROOT}/csse_covid_19_time_series/{CONFIRMED}'\n",
    "    localfile = 'time_series_19-covid-Confirmed.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def getTimeSeriesDeaths(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'{ROOT}/csse_covid_19_time_series/{DEATHS}'\n",
    "    localfile = 'time_series_19-covid-Deaths.csv'\n",
    "    return procUrl(url, download, localfile, force)\n",
    "\n",
    "def getTimeSeriesRecovered(download: bool=False, force: bool=False) -> pd.DataFrame:\n",
    "    url = f'{ROOT}/csse_covid_19_time_series/{RECOVERED}'\n",
    "    localfile = 'time_series_19-covid-Recovered.csv'\n",
    "    return procUrl(url, download, localfile, force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains methods to aggregate each of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` by country.  Note that `force` and `download` are both set `True` in all cases.  Note also that at time of writing `Recovered` isn't supported as a time series dataset in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procTimeSeriesDataframe(r: List, kind: str, log:bool=True) -> pd.DataFrame:\n",
    "    sdf = pd.DataFrame(r)\n",
    "    sdf['day'] = sdf['day'].apply(pd.to_datetime)\n",
    "    if log:\n",
    "        sdf[f'Log{kind}'] = np.log(sdf[kind])\n",
    "    #sdf.set_index('day', drop=True, inplace=True)\n",
    "    return sdf\n",
    "\n",
    "def procTimeSeries(df: pd.DataFrame, kind: str) -> pd.DataFrame:\n",
    "    r = []\n",
    "    countries = df.groupby('Country/Region')\n",
    "    cols = df.columns.to_list()\n",
    "    for country, group in countries:\n",
    "        total = []\n",
    "        for row_index, row in group.iterrows():\n",
    "            rvals = row.to_list()\n",
    "            if not len(total):\n",
    "                total = rvals[4:]\n",
    "                #print('first',total)\n",
    "            else:\n",
    "                #print('next',rvals[4:])\n",
    "                total = [a+b for a, b in zip(total, rvals[4:])]\n",
    "        for a, b in zip(cols[4:], total):\n",
    "            r.append({'day':a, 'country':country, kind:b})\n",
    "    return procTimeSeriesDataframe(r, kind)\n",
    "\n",
    "procTimeSeriesDeaths: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesDeaths(download=True, force=True), 'Deaths')\n",
    "procTimeSeriesConfirmed: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesConfirmed(download=True, force=True), 'Confirmed')\n",
    "procTimeSeriesRecovered: Callable[[pd.DataFrame], pd.DataFrame] = lambda: procTimeSeries(getTimeSeriesRecovered(download=True, force=True), 'Recovered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility method for diffing between any of `[\"Confirmed\",\"Deaths\",\"Recovered\"]` by country to create a `New` column.  This method also adds a log column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def procNewCasesTimeSeries(df: pd.DataFrame, kind:str) -> pd.DataFrame:\n",
    "    r = []\n",
    "    #sdf = df[df.country.isin(countries)].copy()\n",
    "    countryGroups = df.groupby('country')\n",
    "    cols = df.columns.to_list()\n",
    "    cols.append('New')\n",
    "    for country, group in countryGroups:\n",
    "        gdf = group.copy()\n",
    "        gdf['New'] = gdf[kind].diff()\n",
    "        for row_index, row in gdf.iterrows():\n",
    "            r.append(dict(zip(cols,row.to_list())))\n",
    "    ndf = pd.DataFrame(r)\n",
    "    ndf['LogNew'] = np.log(ndf['New'])\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility plotting method for the processed and aggregated time series dataframe.  It has additional support for `altair` to build a log graph using buil-in `alt.Scale` support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plotCountriesTimeSeries(df: pd.DataFrame, countries: List, which: str, x: str, y: str,\n",
    "                            grid: bool=True, log: bool=False, clampx: int=100, clampy: int=7, \n",
    "                            visualisation='matplotlib') -> None:\n",
    "    if visualisation == 'altair':\n",
    "        sdf = df[df.country.isin(countries)]\n",
    "        title = f'{y} by {x} in {countries} as of {which}'\n",
    "        if x=='day':\n",
    "            xval = 'day:T'\n",
    "        else:\n",
    "            if log:\n",
    "                xval = alt.X(f'{x}:Q', scale=alt.Scale(type='log', domain=(clampx, 30000)), axis=alt.Axis(tickCount=8))\n",
    "                sdf = sdf[sdf[x] > clampx]\n",
    "            else:\n",
    "                xval = f'{x}:Q'\n",
    "        if log:\n",
    "            title = f'Log graph of {y} by {x} in {countries} as of {which}'\n",
    "            yval = alt.Y(f'{y}:Q', scale=alt.Scale(type='log'), axis=alt.Axis(tickCount=4))\n",
    "            sdf = sdf[sdf[y] > clampy]\n",
    "        else:\n",
    "            yval = f'{y}:Q'\n",
    "        line_chart = alt.Chart(sdf).mark_line().encode(\n",
    "            x=xval,\n",
    "            y=yval,\n",
    "            color=alt.Color('country:N', scale=alt.Scale(scheme='tableau20'))\n",
    "        ).properties(\n",
    "            width=ALTAIR_W,\n",
    "            height=ALTAIR_H,\n",
    "            title=title\n",
    "        )\n",
    "        if not grid:\n",
    "            line_chart = removeGrid(line_chart)\n",
    "        return line_chart\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        for country in countries:\n",
    "            ax = df[df['country'] == country].plot(ax=ax, x=x, y=y, kind='line', figsize=(18,9))\n",
    "        ax.set_ylabel(y, size=14)\n",
    "        ax.set_xlabel('Day', size=14)\n",
    "        ax.set_title(f'{y} by {x} in {countries} as of {which}', size=18)\n",
    "        ax.legend(ax.get_lines(),countries)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graphing counts and time series via Covid API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains a utility method for plotting a sorted stacked bar graph of country data.  For the `altair` version of the stacked bar graph in `plotCountriesDailyReportFromAPI()`, this requires that we EITHER use [`df.melt()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html) support to convert a wide format dataframe to a long format one OR we use `altair` `transform_fold()` support to manage that conversion for us.\n",
    "```\n",
    "pandas.melt(frame: pandas.core.frame.DataFrame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None) â†’ pandas.core.frame.DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getCountriesDailyReportFromAPI(normalised: bool=False) ->  pd.DataFrame:\n",
    "    url = 'https://api.covid19api.com/summary'\n",
    "    if normalised:\n",
    "        df = pd.DataFrame(requests.get(url).json().get('Countries'))\n",
    "        df.Country.replace({'Iran (Islamic Republic of)': 'Iran', 'Korea, South': 'South Korea'},inplace=True)\n",
    "        cols = df.columns.to_list()\n",
    "        sdf = df.groupby('Country')[cols[2:]].apply(sum).reset_index()\n",
    "        sdf = sdf.sort_values(by=['TotalConfirmed'], ascending=False)\n",
    "    else:\n",
    "        sdf = pd.DataFrame(requests.get(url).json().get('Countries')).\\\n",
    "          sort_values(by=['TotalConfirmed'], ascending=False)\n",
    "    return sdf\n",
    "\n",
    "def plotCountriesDailyReportFromAPI(normalised=False, grid: bool=True, visualisation='matplotlib', cutoff=10, transformFold=True) -> None:\n",
    "    sdf = getCountriesDailyReportFromAPI(normalised)\n",
    "    target = ['TotalRecovered','TotalConfirmed','TotalDeaths']\n",
    "    targetColors = ['green','orange','red']\n",
    "    if visualisation == 'altair':\n",
    "        if transformFold:\n",
    "            bar_chart = alt.Chart(sdf[sdf.TotalDeaths > cutoff]).transform_fold(\n",
    "                target,\n",
    "                as_ = ['Category','Count']\n",
    "            )\n",
    "        else:\n",
    "            sdf2 = sdf[sdf.TotalDeaths > cutoff].melt(id_vars=['Country','Slug'], value_vars=target, var_name='Category', value_name='Count')\n",
    "            bar_chart = alt.Chart(sdf2)\n",
    "        bar_chart = bar_chart.mark_bar(size=10).encode(\n",
    "            x=alt.X('Country',sort='-y'),\n",
    "            y='Count:Q',\n",
    "            order=alt.Order(# Sort the segments of the bars by this field\n",
    "                'Category:N',\n",
    "                sort='descending'\n",
    "            ),\n",
    "            color = alt.Color('Category:N',\n",
    "                scale = alt.Scale(domain=target, range=targetColors),\n",
    "                legend = alt.Legend(title=\"Category\")\n",
    "            )\n",
    "        ).properties(\n",
    "            width=ALTAIR_W,\n",
    "            height=ALTAIR_H,\n",
    "            title='Covid-19 cases and deaths'\n",
    "        )\n",
    "        if not grid:\n",
    "            bar_chart = removeGrid(bar_chart)\n",
    "        return bar_chart\n",
    "    else: # matplotlib\n",
    "        _ = sdf[sdf.TotalDeaths > cutoff].plot(kind='bar', x='Country', y=target,\\\n",
    "          color=targetColors, stacked=True, figsize=(18, 9)).set_title('Covid-19 cases and deaths', size=18)\n",
    "\n",
    "def getCategoryByCountryFromAPI(category: str, country: str, color: str) ->  pd.DataFrame:\n",
    "    url = f'https://api.covid19api.com/total/country/{country}/status/{category.lower()}'\n",
    "    sdf = pd.DataFrame(requests.get(url).json())\n",
    "    sdf['Date'] = sdf['Date'].apply(pd.to_datetime)\n",
    "    sdf.rename(columns={\"Cases\": category}, inplace=True)\n",
    "    sdf[f'Log{category}'] = np.log(sdf[category])\n",
    "    return sdf\n",
    "\n",
    "def plotCategoryByCountryFromAPI(category:str, country:str, color: str='orange', log: bool=False,\n",
    "                                 grid: bool=True, visualisation: str='matplotlib') -> None:\n",
    "    sdf = getCategoryByCountryFromAPI(category, country, color)\n",
    "    if log:\n",
    "        category = f'Log{category}'\n",
    "    if visualisation == 'altair':\n",
    "        line_chart = alt.Chart(sdf).mark_line().encode(\n",
    "            x='Date:T',\n",
    "            y=category,\n",
    "            color=alt.value(color)\n",
    "        ).properties(\n",
    "            width=ALTAIR_W,\n",
    "            height=ALTAIR_H,\n",
    "            title=f'Covid-19 {category} in {country}'\n",
    "        )\n",
    "        if not grid:\n",
    "            line_chart = removeGrid(line_chart)\n",
    "        return line_chart\n",
    "    else: # matplotlib\n",
    "        sdf.plot(kind='line', x='Date', y=category, color=color, figsize=(18, 9)).\\\n",
    "          set_title(f'Covid-19 {category} in {country}', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [the nbdev documentation](http://nbdev.fast.ai/test/):\n",
    "> Everything that is not an exported cell is considered a test, so you should make sure your notebooks can all run smoothly (and fast) if you want to use this functionality as the CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
